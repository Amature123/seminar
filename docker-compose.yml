
x-airflow-common:
  &airflow-common
  build:
    context: .
    dockerfile: ./dags/Dockerfile
    args:
      AIRFLOW_IMAGE_NAME: ${AIRFLOW_IMAGE_NAME}
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__API__AUTH_BACKEND: 'airflow.api.auth.backend.basic_auth'
    PYTHONPATH: /opt/airflow
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./script:/opt/airflow/script
    - ./sql_job:/opt/airflow/sql_job
  user: "${AIRFLOW_UID:-50000}:0"
  depends_on:
    &airflow-common-depends-on
    postgres:
      condition: service_healthy


services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always
    networks:
      - seminar_project

  kafka:
    image: confluentinc/cp-kafka:latest
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_KRAFT_MODE: 'true'  # This enables KRaft mode in Kafka.
      KAFKA_PROCESS_ROLES: controller,broker  # Kafka acts as both broker and controller.
      KAFKA_NODE_ID: 1  # A unique ID for this Kafka instance.
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@localhost:9093"  # Defines the controller voters.
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LOG_DIRS: /var/lib/kafka/data  # Where Kafka stores its logs.
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1  # Since weâ€™re running one broker, one replica is enough.
      KAFKA_LOG_RETENTION_HOURS: 168  # Keep logs for 7 days.
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0  # No delay for consumer rebalancing.
      CLUSTER_ID: "Mk3OEYBSD34fcwNTJENDM2Qk"  
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./data:/var/lib/kafka/data 
    networks:
      - seminar_project

  kafka-init:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - kafka
    entrypoint: >
      sh -c "
      cub kafka-ready -b kafka:9092 1 20 &&
      kafka-topics --create --topic stock_data --bootstrap-server kafka:9092 --partitions 1 --replication-factor 1 || true
      "
    networks:
      - seminar_project

  # cassandra:
  #   image: cassandra:latest
  #   container_name: cassandra
  #   ports:
  #     - "9042:9042"
  #   environment:
  #     MAX_HEAP_SIZE: 512M
  #     HEAP_NEWSIZE: 100M
  #     CASSANDRA_CLUSTER_NAME: "My Cluster"
  #     CASSANDRA_USER: "admin"
  #     CASSANDRA_PASSWORD: "admin"
  #   volumes:
  #     - ./cassandra_data:/var/lib/cassandra 
  #   healthcheck:
  #     test: ["CMD", "cqlsh", "-e", "describe keyspaces"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #   networks:
  #     - seminar_project
  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - 8080:8080
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully
    networks:
      - seminar_project

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}"']
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully
    networks:
      - seminar_project

  airflow-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    command:
      - -c
      - |
        function ver() {
          printf "%04d%04d%04d%04d" $${1//./ }
        }
        one_meg=1048576
        mem_available=$$(($$(getconf _PHYS_PAGES) * $$(getconf PAGE_SIZE) / one_meg))
        cpus_available=$$(grep -cE 'cpu[0-9]+' /proc/stat)
        disk_available=$$(df / | tail -1 | awk '{print $$4}')
        warning_resources="false"
        if (( mem_available < 4000 )) ; then
          echo -e "\033[1;33mWARNING: Not enough memory (recommended: 4GB)\e[0m"
          warning_resources="true"
        fi
        if (( cpus_available < 2 )); then
          echo -e "\033[1;33mWARNING: Not enough CPUs (recommended: 2)\e[0m"
          warning_resources="true"
        fi
        if (( disk_available < one_meg * 10 )); then
          echo -e "\033[1;33mWARNING: Not enough disk (recommended: 10GB)\e[0m"
          warning_resources="true"
        fi
        mkdir -p /opt/airflow/{logs,dags}
        chown -R "${AIRFLOW_UID}:0" /opt/airflow/{logs,dags}
        exec /entrypoint airflow version
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
    user: "0:0"
    networks:
      - seminar_project

  airflow-cli:
    <<: *airflow-common
    profiles:
      - debug
    environment:
      <<: *airflow-common-env
      CONNECTION_CHECK_MAX_COUNT: "0"
    command:
      - bash
      - -c
      - airflow
    networks:
      - seminar_project
      
  jobmanager:
    image: flink:1.19.0
    container_name: jobmanager
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - ./sql_job:/opt/flink/sql_job
    networks:
      - seminar_project
  taskmanager:
    image: flink:1.19.0
    container_name: taskmanager
    depends_on:
      jobmanager:
        condition: service_healthy
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 2

    networks:
      - seminar_project
  sql-client:
    image: flink:1.19.0
    container_name: sql-client
    command: bin/sql-client.sh /opt/flink/sql_job/create_job.sql
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      jobmanager:
        condition: service_healthy
      taskmanager:
        condition: service_healthy

    environment:
    - |
      FLINK_PROPERTIES=
      jobmanager.rpc.address: jobmanager
      rest.address: jobmanager
    networks:
      - seminar_project

networks:
  seminar_project:
    driver: bridge
#########################################################################################
#                                   Multi-node CONFIG                                   #
#                            Warning: heavy load for docker                             #


# services:
#   kafka-controller:
#     image: apache/kafka:3.8.1
#     container_name: kafka-controller
#     environment:
#       KAFKA_NODE_ID: 1
#       KAFKA_PROCESS_ROLES: controller
#       KAFKA_LISTENERS: CONTROLLER://:9093
#       KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
#       KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
#       KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-controller:9093,2@kafka-controller-2:9093
#       KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
#     networks:
#       - seminar_project

#   kafka-controller-2:
#     image: apache/kafka:3.8.1
#     container_name: kafka-controller-2
#     environment:
#       KAFKA_NODE_ID: 2
#       KAFKA_PROCESS_ROLES: controller
#       KAFKA_LISTENERS: CONTROLLER://:9093
#       KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
#       KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
#       KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-controller:9093,2@kafka-controller-2:9093
#       KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
#     networks:
#       - seminar_project

#   kafka_broker:
#     image: apache/kafka:3.8.1
#     container_name: kafka_broker
#     ports:
#       - "29092:9092"
#     environment:
#       KAFKA_NODE_ID: 3
#       KAFKA_PROCESS_ROLES: broker
#       KAFKA_LISTENERS: 'PLAINTEXT://:19092,PLAINTEXT_HOST://:9092'
#       KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka_broker:19092,PLAINTEXT_HOST://localhost:29092'
#       KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
#       KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
#       KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
#       KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-controller:9093,2@kafka-controller-2:9093
#       KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
#     depends_on:
#       - kafka-controller
#       - kafka-controller-2
#     networks:
#       - seminar_project

#   kafka_broker_1:
#     image: apache/kafka:3.8.1
#     container_name: kafka_broker_1
#     ports:
#       - "39092:9092"
#     environment:
#       KAFKA_NODE_ID: 4
#       KAFKA_PROCESS_ROLES: broker
#       KAFKA_LISTENERS: 'PLAINTEXT://:19092,PLAINTEXT_HOST://:9092'
#       KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka_broker_1:19092,PLAINTEXT_HOST://localhost:39092'
#       KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
#       KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
#       KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
#       KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-controller:9093,2@kafka-controller-2:9093
#       KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
#     depends_on:
#       - kafka-controller
#       - kafka-controller-2
#     networks:
#       - seminar_project
      
# networks:
#   seminar_project:
#     driver: bridge

#########################################################################################